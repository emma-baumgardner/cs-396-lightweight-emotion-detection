{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygQ9-flhVMb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1d0bbd-fd26-46cf-e955-64896ccd43be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe\n",
        "!wget -O face_landmarker_v2_with_blendshapes.task -q https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a9TWEoqeKj5M",
        "outputId": "22ffd7e3-9f91-475e-d946-c21536bbeab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.12.0.88)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.3)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.8.0-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-contrib-python (from mediapipe)\n",
            "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.3-py3-none-any.whl (32 kB)\n",
            "Downloading jax-0.7.1-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl (81.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, numpy, sounddevice, opencv-contrib-python, jaxlib, jax, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.12.0.88\n",
            "    Uninstalling opencv-contrib-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-contrib-python-4.12.0.88\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.7.2\n",
            "    Uninstalling jaxlib-0.7.2:\n",
            "      Successfully uninstalled jaxlib-0.7.2\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.7.2\n",
            "    Uninstalling jax-0.7.2:\n",
            "      Successfully uninstalled jax-0.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.7.1 jaxlib-0.7.1 mediapipe-0.10.21 numpy-1.26.4 opencv-contrib-python-4.11.0.86 protobuf-4.25.8 sounddevice-0.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "b207435a37f14cc882e5c32b02b27987"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openface-test"
      ],
      "metadata": {
        "id": "XjpNFXMJDWUZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74185038-5b96-4a77-97b9-2cb19dacece7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openface-test\n",
            "  Downloading openface_test-0.1.26-py3-none-any.whl.metadata (615 bytes)\n",
            "Collecting click==8.1.7 (from openface-test)\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting huggingface_hub==0.21.0 (from openface-test)\n",
            "  Downloading huggingface_hub-0.21.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting imageio==2.34.2 (from openface-test)\n",
            "  Downloading imageio-2.34.2-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting matplotlib==3.10.1 (from openface-test)\n",
            "  Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (from openface-test) (1.26.4)\n",
            "Requirement already satisfied: opencv_contrib_python==4.11.0.86 in /usr/local/lib/python3.12/dist-packages (from openface-test) (4.11.0.86)\n",
            "Collecting opencv_python==4.11.0.86 (from openface-test)\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pandas==2.2.3 (from openface-test)\n",
            "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==9.4.0 (from openface-test)\n",
            "  Downloading Pillow-9.4.0.tar.gz (50.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy==1.13 (from openface-test)\n",
            "  Downloading scipy-1.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.12/dist-packages (from openface-test) (0.13.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from openface-test) (0.25.2)\n",
            "Collecting tensorboardX==2.6.2.2 (from openface-test)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting timm==1.0.15 (from openface-test)\n",
            "  Downloading timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openface-test) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from openface-test) (0.23.0+cu126)\n",
            "Collecting tqdm==4.66.2 (from openface-test)\n",
            "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub==0.21.0->openface-test) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub==0.21.0->openface-test) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub==0.21.0->openface-test) (2.32.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub==0.21.0->openface-test) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub==0.21.0->openface-test) (4.15.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub==0.21.0->openface-test) (25.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.1->openface-test) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.1->openface-test) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.1->openface-test) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.1->openface-test) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.1->openface-test) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.1->openface-test) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3->openface-test) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3->openface-test) (2025.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.12/dist-packages (from tensorboardX==2.6.2.2->openface-test) (4.25.8)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm==1.0.15->openface-test) (0.6.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->openface-test) (3.5)\n",
            "INFO: pip is looking at multiple versions of scikit-image to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting scikit-image (from openface-test)\n",
            "  Downloading scikit_image-0.25.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading scikit_image-0.25.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading scikit_image-0.24.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->openface-test) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->openface-test) (0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->openface-test) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib==3.10.1->openface-test) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openface-test) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openface-test) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub==0.21.0->openface-test) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub==0.21.0->openface-test) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub==0.21.0->openface-test) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub==0.21.0->openface-test) (2025.10.5)\n",
            "Downloading openface_test-0.1.26-py3-none-any.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.8/251.8 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.21.0-py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.1/346.1 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imageio-2.34.2-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_image-0.24.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: Pillow\n",
            "  Building wheel for Pillow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pillow: filename=Pillow-9.4.0-cp312-cp312-linux_x86_64.whl size=1198796 sha256=bbd4ca6f0b1d5c999cb121d00dfa5445f875abd42087e913832bc54147fe8199\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/bd/fa/c7606e3b0644710a556108233c428d43249d98e562ccf055b9\n",
            "Successfully built Pillow\n",
            "Installing collected packages: tqdm, tensorboardX, scipy, Pillow, opencv_python, click, pandas, matplotlib, imageio, huggingface_hub, scikit-image, timm, openface-test\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: opencv_python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.0\n",
            "    Uninstalling click-8.3.0:\n",
            "      Successfully uninstalled click-8.3.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: ImageIO 2.37.2\n",
            "    Uninstalling ImageIO-2.37.2:\n",
            "      Successfully uninstalled ImageIO-2.37.2\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.36.0\n",
            "    Uninstalling huggingface-hub-0.36.0:\n",
            "      Successfully uninstalled huggingface-hub-0.36.0\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.25.2\n",
            "    Uninstalling scikit-image-0.25.2:\n",
            "      Successfully uninstalled scikit-image-0.25.2\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.22\n",
            "    Uninstalling timm-1.0.22:\n",
            "      Successfully uninstalled timm-1.0.22\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "peft 0.17.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.21.0 which is incompatible.\n",
            "diffusers 0.35.2 requires huggingface-hub>=0.34.0, but you have huggingface-hub 0.21.0 which is incompatible.\n",
            "google-adk 1.17.0 requires click<9.0.0,>=8.1.8, but you have click 8.1.7 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "transformers 4.57.1 requires huggingface-hub<1.0,>=0.34.0, but you have huggingface-hub 0.21.0 which is incompatible.\n",
            "gradio 5.49.1 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.21.0 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.0 which is incompatible.\n",
            "datasets 4.0.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.21.0 which is incompatible.\n",
            "datasets 4.0.0 requires tqdm>=4.66.3, but you have tqdm 4.66.2 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.66.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.4.0 click-8.1.7 huggingface_hub-0.21.0 imageio-2.34.2 matplotlib-3.10.1 opencv_python-4.11.0.86 openface-test-0.1.26 pandas-2.2.3 scikit-image-0.24.0 scipy-1.13.0 tensorboardX-2.6.2.2 timm-1.0.15 tqdm-4.66.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              },
              "id": "c419aa90e2cc4041a79c02087f6bc7f6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from openface.multitask_model import MultitaskPredictor\n",
        "from openface.face_detection import FaceDetector\n",
        "import torch\n",
        "\n",
        "from mediapipe import solutions\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mNgbQCfQDYWI",
        "outputId": "a29bb313-85bd-4224-b949-809327d2bc9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_videos(person: str, emotion: str, iter: int) -> cv2.VideoCapture | None:\n",
        "    base_dir = \"/content/drive/MyDrive/video_data/\"\n",
        "    final_filename = f\"{person}_{emotion}_{iter}.mov\"\n",
        "    final_path = os.path.join(base_dir, final_filename)\n",
        "\n",
        "    cap = cv2.VideoCapture(final_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video file at {final_path}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Successfully loaded video: {final_path}\")\n",
        "    return cap\n",
        "\n",
        "video_capture = load_videos(\"keshia\", emotion=\"happy\", iter=1)\n",
        "\n",
        "if video_capture:\n",
        "    video_capture.release()\n"
      ],
      "metadata": {
        "id": "nLJJQtihfM4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005525f1-2764-41fa-94c2-b5073023c6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded video: /content/drive/MyDrive/video_data/keshia_happy_1.mov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def get_euler_angles(matrix: np.ndarray) -> dict:\n",
        "    if matrix is None or matrix.shape != (4, 4):\n",
        "        return {'yaw': np.nan, 'pitch': np.nan, 'roll': np.nan}\n",
        "\n",
        "    R = matrix[:3, :3]\n",
        "    pitch = -np.arcsin(R[2, 0])\n",
        "\n",
        "    yaw = np.arctan2(R[1, 0], R[0, 0])\n",
        "\n",
        "    roll = np.arctan2(R[2, 1], R[2, 2])\n",
        "\n",
        "    yaw_deg = math.degrees(yaw)\n",
        "    pitch_deg = math.degrees(pitch)\n",
        "    roll_deg = math.degrees(roll)\n",
        "\n",
        "    return {'yaw': yaw_deg, 'pitch': pitch_deg, 'roll': roll_deg}\n"
      ],
      "metadata": {
        "id": "E9brqlJH9pZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_model_path = '/content/drive/MyDrive/Alignment_RetinaFace.pth'\n",
        "multitask_model_path = '/content/drive/MyDrive/MTL_backbone.pth'\n",
        "!mkdir -p weights\n",
        "!ln -s \"/content/drive/MyDrive/mobilenetV1X0.25_pretrain.tar\" \"./weights/mobilenetV1X0.25_pretrain.tar\"\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def video_processing(file_path, person, emotion, iteration):\n",
        "  final_output = pd.DataFrame()\n",
        "  try:\n",
        "      multitask_model = MultitaskPredictor(model_path=multitask_model_path, device=device)\n",
        "      face_detector = FaceDetector(model_path=face_model_path, device='cuda')\n",
        "  except NameError:\n",
        "      print(\"Error: MultitaskPredictor class not found. Ensure the custom library is imported.\")\n",
        "      exit()\n",
        "\n",
        "  try:\n",
        "      base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n",
        "      options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
        "                                            output_face_blendshapes=True,\n",
        "                                            output_facial_transformation_matrixes=True,\n",
        "                                            num_faces=1)\n",
        "      detector = vision.FaceLandmarker.create_from_options(options)\n",
        "  except Exception as e:\n",
        "      print(f\"Error initializing MediaPipe FaceLandmarker: {e}\")\n",
        "      return final_output\n",
        "\n",
        "  cap = load_videos(person, emotion, iteration)\n",
        "\n",
        "  if not cap.isOpened():\n",
        "      print(f\"Error: Could not open video file at {file_path}\")\n",
        "      exit()\n",
        "\n",
        "  print(f\"Starting analysis on video: {file_path}\")\n",
        "  frame_count = 0\n",
        "\n",
        "  while cap.isOpened():\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "          break\n",
        "\n",
        "      if not cv2.imwrite('/tmp/temp_frame.jpg', frame):\n",
        "          print(f\"Error: Could not write frame {frame_count} to temporary file.\")\n",
        "          continue\n",
        "\n",
        "      try:\n",
        "          cropped_face, dets = face_detector.get_face('/tmp/temp_frame.jpg')\n",
        "      except NameError:\n",
        "          print(\"Error: 'face_detector' object not defined.\")\n",
        "          cap.release()\n",
        "          exit()\n",
        "\n",
        "      detection_result = None\n",
        "      blendshape_data = {}\n",
        "      pose_angles = {'yaw': np.nan, 'pitch': np.nan, 'roll': np.nan}\n",
        "\n",
        "      try:\n",
        "          rgb_full_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "          mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_full_frame)\n",
        "          detection_result = detector.detect(mp_image)\n",
        "\n",
        "          if detection_result.face_blendshapes and detection_result.face_blendshapes[0]:\n",
        "              for category in detection_result.face_blendshapes[0]:\n",
        "                  blendshape_data[f'bs_{category.category_name}'] = category.score\n",
        "\n",
        "          if detection_result.facial_transformation_matrixes:\n",
        "              matrix = detection_result.facial_transformation_matrixes[0]\n",
        "              pose_angles = get_euler_angles(matrix)\n",
        "      except Exception as e:\n",
        "          print(f\"Frame {frame_count}: MediaPipe detection failed: {e}\")\n",
        "\n",
        "      if cropped_face is not None and dets is not None:\n",
        "\n",
        "          with torch.no_grad():\n",
        "            emotion_logits, gaze_output, au_output = multitask_model.predict(cropped_face)\n",
        "          emotion_index = torch.argmax(emotion_logits, dim=1).item()\n",
        "          gaze_data = gaze_output.cpu().squeeze().numpy()\n",
        "          au_data = au_output.cpu().squeeze().numpy()\n",
        "\n",
        "          # print(f\"Frame {frame_count}: Emotion Index: {emotion_index}, Gaze: {gaze_data}, AU shape: {au_output.shape}\")\n",
        "          new_row_data = {\n",
        "              'frame_count': frame_count,\n",
        "              'emotion_index': emotion_index,\n",
        "              'gaze_yaw': gaze_data[0] if gaze_data.size > 0 else np.nan,\n",
        "              'gaze_pitch': gaze_data[1] if gaze_data.size > 1 else np.nan,\n",
        "              'au_shape_dim1': au_data[0] if au_data.size > 0 else np.nan,\n",
        "              'au_shape_dim2': au_data[1] if au_data.size > 1 else np.nan,\n",
        "              'au_shape_dim3': au_data[2] if au_data.size > 1 else np.nan,\n",
        "              'au_shape_dim4': au_data[3] if au_data.size > 1 else np.nan,\n",
        "              'au_shape_dim5': au_data[4] if au_data.size > 1 else np.nan,\n",
        "              'au_shape_dim6': au_data[5] if au_data.size > 1 else np.nan,\n",
        "              'au_shape_dim7': au_data[6] if au_data.size > 1 else np.nan,\n",
        "              'au_shape_dim8': au_data[7] if au_data.size > 1 else np.nan,\n",
        "\n",
        "              'mp_pose_yaw_deg': pose_angles['yaw'],\n",
        "              'mp_pose_pitch_deg': pose_angles['pitch'],\n",
        "              'mp_pose_roll_deg': pose_angles['roll'],\n",
        "              'detection_result': 'Extracted Data' if blendshape_data or pose_angles['yaw'] is not np.nan else 'No MP Data'\n",
        "          }\n",
        "          new_row_data.update(blendshape_data)\n",
        "          new_row_df = pd.DataFrame(new_row_data, index=[0])\n",
        "          final_output = pd.concat([final_output, new_row_df], ignore_index=True)\n",
        "      else:\n",
        "          print(f\"Frame {frame_count}: No face detected.\")\n",
        "\n",
        "      frame_count += 1\n",
        "\n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()\n",
        "  print(\"Video processing complete.\")\n",
        "  return final_output"
      ],
      "metadata": {
        "id": "TAIr9kA1pbMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# people = ['keshia', 'fai', 'emma', 'grant]\n",
        "people = ['grant']\n",
        "emotions = ['angry', 'happy', 'sad', 'fear', 'disgust', 'neutral', 'surprise']\n",
        "# emotions = ['surprise']\n",
        "!mkdir -p processed_videos\n",
        "\n",
        "for person in people:\n",
        "  for emotion in emotions:\n",
        "    for i in range(1,11):\n",
        "      file_path = f\"/content/drive/MyDrive/video_data/{person}_{emotion}_{i}.mov\"\n",
        "      processed_video = video_processing(file_path, person, emotion, i)\n",
        "      processed_video.reset_index(inplace = True, drop = True)\n",
        "      processed_video.to_csv(f\"processed_videos/{person}_{emotion}_{i}_processed.csv\", index = 'ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs6l3MVZ4eYh",
        "outputId": "c7507efa-0d19-4918-e972-e7032b7f9ec9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_angry_1.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_angry_1.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_angry_2.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_angry_2.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_angry_3.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_angry_3.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_angry_4.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_angry_4.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_angry_5.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_angry_5.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_angry_6.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_angry_6.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_angry_7.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_angry_7.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_angry_8.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_angry_8.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_angry_9.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_angry_9.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_angry_10.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_angry_10.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_happy_1.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_happy_1.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_happy_2.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_happy_2.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_happy_3.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_happy_3.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_happy_4.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_happy_4.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_happy_5.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_happy_5.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_happy_6.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_happy_6.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_happy_7.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_happy_7.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_happy_8.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_happy_8.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_happy_9.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_happy_9.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_happy_10.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_happy_10.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_sad_1.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_sad_1.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_sad_2.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_sad_2.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_sad_3.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_sad_3.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_sad_4.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_sad_4.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_sad_5.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_sad_5.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_sad_6.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_sad_6.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_sad_7.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_sad_7.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_sad_8.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_sad_8.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_sad_9.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_sad_9.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_sad_10.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_sad_10.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_fear_1.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_fear_1.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_fear_2.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_fear_2.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_fear_3.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_fear_3.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_fear_4.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_fear_4.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_fear_5.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_fear_5.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_fear_6.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_fear_6.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_fear_7.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_fear_7.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_fear_8.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_fear_8.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_fear_9.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_fear_9.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_fear_10.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_fear_10.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_disgust_1.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_disgust_1.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_disgust_2.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_disgust_2.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_disgust_3.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_disgust_3.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_disgust_4.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_disgust_4.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_disgust_5.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_disgust_5.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_disgust_6.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_disgust_6.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_disgust_7.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_disgust_7.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_disgust_8.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_disgust_8.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_disgust_9.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_disgust_9.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_disgust_10.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_disgust_10.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_neutral_1.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_neutral_1.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_neutral_2.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_neutral_2.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_neutral_3.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_neutral_3.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_neutral_4.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_neutral_4.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_neutral_5.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_neutral_5.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_neutral_6.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_neutral_6.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_neutral_7.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_neutral_7.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_neutral_8.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_neutral_8.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_neutral_9.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_neutral_9.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_neutral_10.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_neutral_10.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_surprise_1.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_surprise_1.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_surprise_2.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_surprise_2.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_surprise_3.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_surprise_3.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_surprise_4.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_surprise_4.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_surprise_5.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_surprise_5.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_surprise_6.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_surprise_6.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_surprise_7.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_surprise_7.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_surprise_8.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_surprise_8.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_surprise_9.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_surprise_9.mov\n",
            "Video processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading multitask model from /content/drive/MyDrive/MTL_backbone.pth...\n",
            "Loading pretrained model from /content/drive/MyDrive/Alignment_RetinaFace.pth\n",
            "remove prefix 'module.'\n",
            "Missing keys:0\n",
            "Unused checkpoint keys:0\n",
            "Used keys:300\n",
            "Successfully loaded video: /content/drive/MyDrive/video_data/grant_surprise_10.mov\n",
            "Starting analysis on video: /content/drive/MyDrive/video_data/grant_surprise_10.mov\n",
            "Video processing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "shutil.make_archive('processed_videos_grant', 'zip', 'processed_videos_grant')\n",
        "# files.download('processed_videos.zip')\n",
        "files.download('processed_videos_grant.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BQBfPQrGwm_j",
        "outputId": "a071ade0-95f8-477f-8e0c-d66318766da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_df9b6cb3-e860-4992-b32f-c57c8bbd9940\", \"processed_videos_grant.zip\", 2971336)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XW951iFJlM0i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}